{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zcwisc/GB657/blob/main/Module_1_FraudDetectionViaLOF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fraud Detection via Local Outlier Factor Anomaly Detection\n",
        "\n",
        "One area of application for *anomaly detecation* is identifying **fraud**, e.g. in financial or insurance transactions. There are several key reasons of why anomaly detection, as opposed or in addition to supervised learning / classification (i.e., predicting the \"fraud\" label), is useful here:\n",
        "- Often we only know of very limited transactions that they were fraudulent; many fraud cases may not have been detected.\n",
        "- Fraudsters may change their strategies; just \"learning\" what characterizied a fraud detection in the past may not be appropopriate.\n",
        "\n",
        "## Local Outlier Factor for Anomaly Detection\n",
        "\n",
        "We consider fraud detection via **Local Outlier Factor** Anomaly Detection. From [this Kaggle Codebook](https://www.kaggle.com/code/vijeetnigam26/credit-card-fraud-detection):\n",
        "\n",
        "- LOF (Local Outlier Factor) is an unsupervised anomaly detection algorithm that assesses the local density deviation of a data point compared to its neighbors. It quantifies the degree of abnormality of a data point based on its relative density.\n",
        "\n",
        "<img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F1341832%2F27b93ecfd56afa80040f9b1ebecccbed%2F1_217TN2_-cgZ1d7hZUWhYUA.png?generation=1600286513104059&alt=media\" height=25% width=35% style=\"text-align:center;\">\n",
        "\n",
        "- The LOF algorithm works by calculating a local reachability density for each data point, which represents how isolated or tightly grouped the point is compared to its neighbors. Anomaly scores are assigned based on the degree to which a point's density deviates from the density of its neighbors. Points with significantly lower density compared to their neighbors are considered outliers with higher LOF scores.\n",
        "\n",
        "- LOF is effective in identifying anomalies in datasets with varying densities or clusters of different sizes. It can handle data with complex structures and does not rely on strict assumptions about the data distribution. LOF provides a local perspective on anomalies, allowing for more fine-grained anomaly detection in the dataset.\n",
        "\n",
        "So let's take a look."
      ],
      "metadata": {
        "id": "JNGZbbCiRkR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "### Preparatory Steps\n",
        "\n",
        "As usually, let's clone our git repository so as to have access to the data."
      ],
      "metadata": {
        "id": "6xa9J22nR22l"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7rMHNGajOvV"
      },
      "source": [
        "!git clone https://github.com/zcwisc/GB657.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's install some relevant libraries."
      ],
      "metadata": {
        "id": "DvC0N_VKSFaw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5yZYbDPGZBq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report,accuracy_score, confusion_matrix\n",
        "from sklearn.neighbors import LocalOutlierFactor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kaggle Credit Card Fraud Dataset\n",
        "\n",
        "We use a sample of a dataset on credit card transactions (with some known fraudulent cases from kaggle). The real dataset has about 250K transactions, but we use a small sample for ease of computation (you can try it out on the larger dataset!):"
      ],
      "metadata": {
        "id": "JHQWCbsgsFt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ccdata = pd.read_csv('GB657/Module_1_CreditCardFraud_sample.csv', index_col=0)"
      ],
      "metadata": {
        "id": "rgjKOFoSsivE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccdata.head()"
      ],
      "metadata": {
        "id": "USMRBYm-Enoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data contains a sample of credict card transactions in 9/2013 by European cardholders over two dates. It contains only numerical features V1-V28, which appears to be resulting from transformations (details were protected by the company). We also have 'Time' and 'Amount': 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset, and 'Amount' is the transaction Amount. Importantly, 'Class' is the response variable and it takes value 1 in case the transaction was fraudulent.\n",
        "\n",
        "Since we have little interpretable information, we won't dive into a detailed *exploratory data analysis* (you should in an actual application, though), and simply jump into the anomaly detection. We use for 'X' our feature matrix and our 'y' is the information on whether it's fraudulent:"
      ],
      "metadata": {
        "id": "Kzyhlx-pMMo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = ccdata.drop('Class', axis=1)\n",
        "y = ccdata['Class']"
      ],
      "metadata": {
        "id": "767ajO28H3F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Anomaly Detection via Local Outlier Factor\n",
        "\n",
        "We consider the local outlier factor analysis. As an input factor, we need to set the number of possible outliers. We use experience value: there are around 500 of the 290K transactions that are fraudulent, resulting in about one in 500. However, we may have a sense that we miss about one in two of fraudulent transactions, so we set:"
      ],
      "metadata": {
        "id": "aIuwwWA3Er5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_fraction = 1/250"
      ],
      "metadata": {
        "id": "y8IvocvHGa-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We rely on the default parameter otherwise (check the [documentation](https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.LocalOutlierFactor.html) for details):"
      ],
      "metadata": {
        "id": "_qxEfJzlMD8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LOF_detect = LocalOutlierFactor(contamination=outlier_fraction)"
      ],
      "metadata": {
        "id": "aKCml2VRGPxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We consider the samples that are detected as fraudulent:"
      ],
      "metadata": {
        "id": "fUCd0z2qMaf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = LOF_detect.fit_predict(X)"
      ],
      "metadata": {
        "id": "19m3HDboHzLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output here is '1' for non-outliers and '-1' for outliers:"
      ],
      "metadata": {
        "id": "c99taA0AMkdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outliers = (y_pred == -1)"
      ],
      "metadata": {
        "id": "Dvu6jQoyIKvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize via a confusion matrix with the known fraud cases:"
      ],
      "metadata": {
        "id": "3_H7P80gM6Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y, outliers)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=['Not Outlier', 'Outlier'],\n",
        "            yticklabels=['Not Outlier', 'Outlier'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3wLC4TfBJJ9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, 7 of the detected 166 outliers are fraudulent---and we are missing 45 cases. So, it doesn't perform very well. However, it appears from the [work by others](https://www.kaggle.com/code/vijeetnigam26/credit-card-fraud-detection) that for the full dataset, we get better results with this approach. We can also work on tuning the approach some more.  "
      ],
      "metadata": {
        "id": "r-fhZuqeK67W"
      }
    }
  ]
}